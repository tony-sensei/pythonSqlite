{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The output in looker studio:\n",
    "[LINK](https://lookerstudio.google.com/embed/reporting/2d94a92e-7881-4adf-bfd7-c32a2c5b77fb/page/axcID)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BiClustering with KMeans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import SpectralBiclustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tony/PycharmProjects/pythonSqlite/venv/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Detect the file encoding\n",
    "with open('testHeatRawData1.csv', 'rb') as file:\n",
    "    raw_data = file.read()\n",
    "    encoding = chardet.detect(raw_data)['encoding']\n",
    "\n",
    "# Read the CSV file with the detected encoding and convert it to a DataFrame\n",
    "data = pd.read_csv('testHeatRawData1.csv', encoding=encoding, delimiter='\\t')\n",
    "\n",
    "# Prepare the data for biclustering\n",
    "pivot_data = data.pivot_table(index='Child Id', columns='Name', values='Score').fillna(0)\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(pivot_data)\n",
    "\n",
    "# Perform clustering using k-means\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "kmeans.fit(standardized_data)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Add cluster labels to the original pivot data\n",
    "pivot_data['Cluster'] = labels\n",
    "\n",
    "pivot_data = pivot_data.astype(int)\n",
    "pivot_data = pivot_data.reset_index()\n",
    "\n",
    "# Melt the data into a long format\n",
    "melted_data = pd.melt(pivot_data, id_vars=['Child Id', 'Cluster'], value_vars=['RIDELA', 'RSDQB', 'RSDQE', 'RSDQH', 'RSDQP'], var_name='Category', value_name='Score')\n",
    "\n",
    "# Save the clustered data to a CSV file\n",
    "melted_data.to_csv('clustering_data.csv', index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Detect the file encoding\n",
    "with open('testHeatRawData1.csv', 'rb') as file:\n",
    "    raw_data = file.read()\n",
    "    encoding = chardet.detect(raw_data)['encoding']\n",
    "\n",
    "# Read the CSV file with the detected encoding and convert it to a DataFrame\n",
    "data = pd.read_csv('testHeatRawData1.csv', encoding=encoding, delimiter='\\t')\n",
    "\n",
    "# Prepare the data for biclustering\n",
    "pivot_data = data.pivot_table(index='Child Id', columns='Name', values='Score').fillna(0)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(pivot_data)\n",
    "\n",
    "# Perform biclustering using SpectralBiclustering\n",
    "biclustering = SpectralBiclustering(n_clusters=(5,3), random_state=0) # 5 row cluster, 3 column cluster\n",
    "biclustering.fit(standardized_data)\n",
    "\n",
    "# Add row and column cluster labels\n",
    "pivot_data['Row Cluster'] = biclustering.row_labels_\n",
    "pivot_data.loc['Column Cluster'] = np.append(biclustering.column_labels_, -1)  # Add a dummy value for 'Row Cluster'\n",
    "\n",
    "# Rearrange the data according to the biclusters\n",
    "row_order = np.argsort(biclustering.row_labels_)\n",
    "column_order = np.argsort(np.append(biclustering.column_labels_, -1))  # Include the dummy value for 'Row Cluster'\n",
    "biclustered_data = pivot_data.iloc[row_order].T.iloc[column_order].T\n",
    "\n",
    "biclustered_data = pivot_data.astype(int)\n",
    "\n",
    "\n",
    "# Save the biclustered data to a CSV file\n",
    "biclustered_data.to_csv('biclustered_data.csv', index=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
